# Example LLM Configuration: Multi-Provider Setup
# This shows how to use different providers for different agents

# Available LLM Providers
providers:
  google:
    class: "langchain_google_genai.ChatGoogleGenerativeAI"
    models:
      - "gemini-1.5-flash-latest"
      - "gemini-1.5-pro-latest"
      - "gemini-pro"
    default_params:
      temperature: 0.1
      
  openai:
    class: "langchain_openai.ChatOpenAI"
    models:
      - "gpt-4o"
      - "gpt-4o-mini" 
      - "gpt-3.5-turbo"
    default_params:
      temperature: 0.1
      
  anthropic:
    class: "langchain_anthropic.ChatAnthropic"
    models:
      - "claude-3-5-sonnet-20241022"
      - "claude-3-haiku-20240307"
    default_params:
      temperature: 0.1

# Agent-specific configurations - showing mixed providers
agents:
  planner:
    provider: "anthropic"  # Use Claude for strategic planning
    model: "claude-3-5-sonnet-20241022"
    temperature: 0.1
    description: "Strategic planning with Claude's reasoning"
    
  code_generator:
    provider: "openai"  # Use GPT-4 for code generation
    model: "gpt-4o"
    temperature: 0.2
    description: "Code generation with GPT-4"
    
  corrector:
    provider: "google"  # Use Gemini for corrections
    model: "gemini-1.5-flash-latest"
    temperature: 0.1
    description: "Fast corrections with Gemini Flash"
    
  critique:
    provider: "anthropic"  # Use Claude for detailed review
    model: "claude-3-5-sonnet-20241022"
    temperature: 0.0
    description: "Thorough code review with Claude"
    
  reasoner:
    provider: "openai"  # Use GPT for reasoning
    model: "gpt-4o"
    temperature: 0.1
    description: "Symbolic reasoning with GPT-4"
    
  verifier:
    provider: "google"  # Use Gemini for fast verification
    model: "gemini-1.5-flash-latest"
    temperature: 0.0
    description: "Fast verification with Gemini"

  docker_agent:
    provider: "google"  # Use Gemini for Docker specs
    model: "gemini-1.5-pro-latest"  # Use Pro for complex analysis
    temperature: 0.3
    description: "Docker analysis with Gemini Pro"

# Global defaults (used for agents not specifically configured)
defaults:
  provider: "google"
  model: "gemini-1.5-flash-latest"
  temperature: 0.1
  max_tokens: 4096
  timeout: 30

# Environment variables mapping
env_vars:
  google: "GOOGLE_API_KEY"
  openai: "OPENAI_API_KEY"
  anthropic: "ANTHROPIC_API_KEY"
